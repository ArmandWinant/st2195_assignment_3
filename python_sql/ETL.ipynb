{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d911d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import re\n",
    "from io import BytesIO\n",
    "import bz2\n",
    "from datetime import datetime, time\n",
    "from sql_queries import create_table_queries, drop_table_queries, planes_table_insert,  carriers_table_insert, airports_table_insert, on_time_table_insert\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0f8df82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeFloatToDatetime(timeFloat):\n",
    "    if pd.notna(timeFloat):        \n",
    "        hour = int(timeFloat // 100) % 24\n",
    "        minute = int(timeFloat % 100)\n",
    "        \n",
    "        return time(hour = hour, minute = minute)\n",
    "    return timeFloat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7c1326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_db():\n",
    "    db_filename = \"airline2.db\"\n",
    "        \n",
    "    # remove the db file if it exists\n",
    "    try:\n",
    "        os.remove(db_filename)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    \n",
    "    # create database and open connection\n",
    "    conn = sqlite3.connect(db_filename)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    return cur, conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2745cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_tables(cur, conn):\n",
    "    \"\"\"\n",
    "    Drops each table using the queries in `drop_table_queries` list.\n",
    "    \"\"\"\n",
    "    for query in drop_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aff2894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tables(cur, conn):\n",
    "    \"\"\"\n",
    "    Creates each table using the queries in `create_table_queries` list. \n",
    "    \"\"\"\n",
    "    for query in create_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c768611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv_file(file_name, cur, insert_query):\n",
    "    df = pd.read_csv(file_name)\n",
    "    cur.executemany(insert_query, df.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a32f2f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_bz2_file(file_name, cur, insert_query):\n",
    "    with bz2.open(file_name, \"rb\") as f:\n",
    "        data = f.read()\n",
    "        df = pd.read_csv(BytesIO(data), encoding='latin_1')\n",
    "        cur.executemany(insert_query, df.values.tolist())\n",
    "        \n",
    "#         df.DepTime = df.DepTime.apply(timeFloatToDatetime)\n",
    "#         df.ArrTime = df.ArrTime.apply(timeFloatToDatetime)\n",
    "#         df.CRSDepTime = df.CRSDepTime.apply(timeFloatToDatetime)\n",
    "#         df.CRSArrTime = df.CRSArrTime.apply(timeFloatToDatetime)\n",
    "        \n",
    "#         for _, row in df.iterrows():\n",
    "#             record_list.append(row)\n",
    "#         cur.executemany(insert_query, record_list)\n",
    "#             cur.execute(insert_query, list(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "063d3487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(cur, conn):\n",
    "    \"\"\"\n",
    "    Description: This function is responsible for listing the files in a directory,\n",
    "    and then executing the ingest process for each file according to the function\n",
    "    that performs the transformation to save it to the database.\n",
    "\n",
    "    Arguments:\n",
    "        cur: the cursor object.\n",
    "        conn: connection to the database.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    data_directory = str(Path.home()) + \"/Desktop/University/data-science-and-business-analytics/programming-for-data-science/dataverse_files/\"\n",
    "    \n",
    "    # get all files matching extension from directory\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(data_directory):\n",
    "        files = glob.glob(os.path.join(root,'*'))\n",
    "        for f in files :\n",
    "            all_files.append(os.path.abspath(f))\n",
    "\n",
    "    # iterate over files and process\n",
    "    for i, datafile in enumerate(all_files, 1):\n",
    "        if datafile.endswith('plane-data.csv'):\n",
    "            process_csv_file(datafile, cur, planes_table_insert)\n",
    "            conn.commit()\n",
    "            print('Planes file upload successful')\n",
    "        elif datafile.endswith('carriers.csv'):\n",
    "            process_csv_file(datafile, cur, carriers_table_insert)\n",
    "            conn.commit()\n",
    "            print('Carriers file upload successful')\n",
    "        elif datafile.endswith('airports.csv'):\n",
    "            process_csv_file(datafile, cur, airports_table_insert)\n",
    "            conn.commit()\n",
    "            print('Airports file upload successful')\n",
    "        else:\n",
    "            match = re.search(r'200(0|1|2|3|4|5){1}.csv.bz2$', datafile)\n",
    "\n",
    "            if match:\n",
    "                process_bz2_file(datafile, cur, on_time_table_insert)\n",
    "                conn.commit()\n",
    "                print(\"Flight file upload successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56843a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aws_connect():\n",
    "    \"\"\"\n",
    "    Description: This function is responsible for establishing the interface with the AWS S3 bucket where the database\n",
    "    file should be stored.\n",
    "\n",
    "    Arguments:\n",
    "        None\n",
    "\n",
    "    Returns:\n",
    "        Boto3 client and resource objects\n",
    "    \"\"\"\n",
    "    access_keys = get_aws_access_keys()\n",
    "    \n",
    "    # Creating the low level functional client\n",
    "    client = boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id = access_keys['AWSAccessKeyId'],\n",
    "        aws_secret_access_key = access_keys['AWSSecretKey'],\n",
    "        region_name = 'eu-central-1'\n",
    "    )\n",
    "\n",
    "    # Creating the high level object oriented interface\n",
    "    resource = boto3.resource(\n",
    "        's3',\n",
    "        aws_access_key_id = access_keys['AWSAccessKeyId'],\n",
    "        aws_secret_access_key = access_keys['AWSSecretKey'],\n",
    "        region_name = 'eu-central-1'\n",
    "    )\n",
    "    \n",
    "    return client, resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32691a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aws_access_keys():\n",
    "    \"\"\"\n",
    "    Description: This function retrieves access keys for the AWS S3 bucket where the database file is to be stored.\n",
    "    \n",
    "\n",
    "    Arguments:\n",
    "        None\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing values for AWSAccessKeyId and AWSSecretKey\n",
    "    \"\"\"\n",
    "    file_name = data_directory = str(Path.home()) + \"/Desktop/University/data-science-and-business-analytics/programming-for-data-science/st2195_assignment_3/rootkey.csv\"\n",
    "    key_dictionary = {}\n",
    "    with open(file_name, \"r\") as file:\n",
    "        for line in file.readlines():\n",
    "            key_dictionary[line.split(\"=\")[0].strip()] = line.split(\"=\")[1].strip()\n",
    "    \n",
    "    return key_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "188ea3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_dbfile(filename):\n",
    "    \"\"\"\n",
    "    Description: This function is responsible for uploading a given database file to the designated AWS S3 bucket.\n",
    "    Once succesfully uploaded, the local file is deleted.\n",
    "\n",
    "    Arguments:\n",
    "        filename (string): name of the database file (format-agnostic)\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # generate AWS interface objects\n",
    "    client, resource = aws_connect()\n",
    "    \n",
    "    try:   \n",
    "        # open the file and upload to S3 bucket\n",
    "        with open(filename, 'rb') as data:\n",
    "            client.upload_fileobj(data, 'flights-db', 'db-file')\n",
    "\n",
    "        # delete the local file\n",
    "        os.remove(filename)\n",
    "    except ClientError as e:\n",
    "        print(\"Error uploading database file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dd1b0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 files found in /Users/bastienwinant/Desktop/University/data-science-and-business-analytics/programming-for-data-science/dataverse_files/\n",
      "9/26 files processed.\n",
      "10/26 files processed.\n",
      "12/26 files processed.\n",
      "19/26 files processed.\n",
      "23/26 files processed.\n",
      "24/26 files processed.\n"
     ]
    }
   ],
   "source": [
    "# initialize a new db\n",
    "cur, conn = initialise_db()\n",
    "create_tables(cur, conn)\n",
    "\n",
    "process_data(cur, conn)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "upload_dbfile('airline2.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4e7116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5be5ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
