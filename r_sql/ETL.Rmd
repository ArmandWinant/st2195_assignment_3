---
title: "Practice assignment 3 - ETL"
output:
  html_document:
    df_print: paged
---

## *R*
> Load the files of [this dataset](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/HG7NV7) into an SQLite database.

```{r}
source("create_tables.R")
```

#### Reading and uploading the data
Read the data into Pandas dataframes, and leverage to_sql method to create and fill tables.
```{r}
process_data_file <- function(file, conn, table_name) {
  df <- read.csv(file, header = TRUE)
  dbWriteTable(conn, table_name, df, append = TRUE)
}
```

#### Apply ETL scripts to input files
Loop through the files and selectively launch ETL scripts to store the data in SQLite tables.
```{r}
process_data <- function(conn) {
  working_directory = getwd()
  setwd('../../dataverse_files')
  
  for (file in list.files()) {
    if (endsWith(file, 'bz2') && (grepl('^200(0|1|2|3|4|5){1}', file, ignore.case=FALSE))) {
      process_data_file(file, conn, "on_time")
    } else if (startsWith(file, 'plane-data')) {
      process_data_file(file, conn, "planes")
    } else if (startsWith(file, "carriers")) {
      process_data_file(file, conn, "carriers")
    } else if (startsWith(file, "airports")) {
      process_data_file(file, conn, "airports")
    }
  }
  
  # restore the initial working directory
  setwd(working_directory)
}
```

#### Run the database initialisation and uploading functions, then close connection.
```{r}
conn = initialise_db()
process_data(conn)
dbDisconnect(conn)
```

